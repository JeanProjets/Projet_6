# üéôÔ∏è Script de Soutenance D√©taill√© (Dur√©e cible : 20 min)

---

## 1. Introduction & Contexte (0:00 - 0:02)
"Bonjour √† tous. Je suis ravi de vous pr√©senter aujourd'hui les r√©sultats de ma mission pour la marketplace e-commerce. Notre client fait face √† un d√©fi de croissance : avec des milliers de nouveaux articles chaque jour, l'attribution manuelle des cat√©gories par les vendeurs est devenue une source d'erreurs et de frustration. Mon r√¥le a √©t√© de concevoir un syst√®me automatis√© de classification, capable d'analyser √† la fois le descriptif textuel et l'image du produit."

---

## 2. Pr√©sentation du Dataset (0:02 - 0:04)
"Pour ce projet, nous avons utilis√© un √©chantillon du catalogue Flipkart. Ce dataset est compos√© de 1050 produits. Un point crucial pour la fiabilit√© de nos futurs mod√®les est que le jeu de donn√©es est parfaitement √©quilibr√© : nous avons 150 articles pour chacune des 7 cat√©gories. Cela nous pr√©munit contre les biais de classification o√π un mod√®le pourrait favoriser une classe sur-repr√©sent√©e."

---

## 3. Pr√©traitement NLP : Pourquoi la Lemmatisation ? (0:04 - 0:07)
"Entrons dans la technique avec le traitement du texte. J'ai mis en place un pipeline de nettoyage classique : suppression des balises HTML, de la ponctuation et des 'stop-words'. 
Mais j'aimerais m'attarder sur le choix entre le Stemming et la Lemmatisation. L√† o√π le stemming coupe simplement la fin des mots, la lemmatisation utilise un dictionnaire pour ramener le mot √† sa forme canonique. J'ai choisi la lemmatisation car elle pr√©serve mieux le sens s√©mantique, ce qui est vital pour diff√©rencier des produits techniques."

---

## 4. Pr√©traitement Vision : Pr√©parer le CNN (0:07 - 0:09)
"C√¥t√© image, le d√©fi est la standardisation. Les r√©seaux de neurones convolutionnels imposent une taille d'entr√©e fixe. J'ai donc redimensionn√© tous les visuels en 224x224 pixels. J'ai √©galement appliqu√© une normalisation des pixels. En ramenant les valeurs de 0 √† 255 vers une √©chelle plus petite, on aide l'optimiseur √† converger beaucoup plus rapidement lors de l'entra√Ænement."

---

## 5. Extraction de Features : De TF-IDF aux Transformers (0:09 - 0:12)
"Pour transformer le texte en vecteurs, j'ai test√© plusieurs m√©thodes. 
Le TF-IDF est excellent pour capter la raret√© des mots : un mot comme 'LCD' appara√Ætra peu souvent mais sera tr√®s discriminant pour la cat√©gorie 'Computers'.
Cependant, pour capter le contexte, je suis pass√© aux Embeddings avec BERT et l'Universal Sentence Encoder. Ces mod√®les 'comprennent' que 'fauteuil' et 'si√®ge' partagent une proximit√© s√©mantique, l√† o√π les m√©thodes fr√©quentielles √©chouent."

---

## 6. SIFT et Bag of Visual Words (0:12 - 0:14)
"Pour l'image, j'ai d'abord test√© l'approche classique SIFT. C'est un algorithme qui d√©tecte des points d'int√©r√™t (angles, bords). J'ai ensuite utilis√© une technique de 'Bag of Visual Words' : on groupe les milliers de descripteurs SIFT en 'clusters' pour cr√©er un dictionnaire de formes. Chaque image est alors d√©finie par la fr√©quence de ces formes. C'est une approche robuste mais gourmande en calcul."

---

## 7. Deep Learning : La puissance du Transfer Learning (0:14 - 0:16)
"L'approche la plus performante a √©t√© le Transfer Learning. J'ai utilis√© VGG16, un mod√®le d√©j√† entra√Æn√© sur des millions d'images. Plut√¥t que de repartir de z√©ro, j'utilise sa capacit√© √† extraire des formes complexes. J'ai extrait les features de la derni√®re couche de convolution. Comme on le voit sur le graphique t-SNE, cette m√©thode produit les clusters les plus nets, avec un score ARI de 0.69, ce qui est tr√®s √©lev√© pour du clustering non supervis√©."

---

## 8. Classification Supervis√©e : R√©sultats (0:16 - 0:18)
"Fort de ces r√©sultats, j'ai entra√Æn√© un classifieur supervis√©. Pour √©viter l'overfitting, j'ai utilis√© la 'Data Augmentation' : en faisant pivoter ou en zoomant sur les images, on cr√©e virtuellement de nouveaux exemples. 
Le mod√®le final atteint 83.3% d'accuracy sur le test set. L'analyse par classe montre que nous sommes excellents sur les montres, mais que nous avons encore des marges de progression sur la distinction entre d√©coration et ameublement."

---

## 9. API et Conclusion (0:18 - 0:20)
"Enfin, j'ai int√©gr√© une brique de collecte de donn√©es via l'API OpenFood Facts. Ce script permet d'automatiser l'ajout de nouveaux produits comme le Champagne, en r√©cup√©rant les ingr√©dients et les visuels. 
Pour conclure, ce projet valide la faisabilit√© d'une classification hybride. Pour une mise en production, je recommanderais un mod√®le multimodal 'late-fusion' qui ferait la moyenne des pr√©dictions du texte et de l'image. Merci de m'avoir √©cout√©."
