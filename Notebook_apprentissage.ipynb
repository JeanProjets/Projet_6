{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0156ea07",
   "metadata": {},
   "source": [
    "# Apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0330a3ce",
   "metadata": {},
   "source": [
    "## Stemming, lemming, tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "503a5548",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/j/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/j/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/j/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to /Users/j/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: The runners were running quickly through the beautiful gardens, carrying heavy boxes.\n",
      "\n",
      "============================================================\n",
      "\n",
      "1. TOKENIZATION:\n",
      "['the', 'runners', 'were', 'running', 'quickly', 'through', 'the', 'beautiful', 'gardens', ',', 'carrying', 'heavy', 'boxes', '.']\n",
      "\n",
      "============================================================\n",
      "\n",
      "2a. STEMMING (Porter Stemmer):\n",
      "['the', 'runner', 'were', 'run', 'quickli', 'through', 'the', 'beauti', 'garden', ',', 'carri', 'heavi', 'box', '.']\n",
      "\n",
      "Examples:\n",
      "  running → run\n",
      "  runner → runner\n",
      "  beautiful → beauti\n",
      "\n",
      "============================================================\n",
      "\n",
      "2b. LEMMATIZATION:\n",
      "['the', 'runners', 'be', 'run', 'quickly', 'through', 'the', 'beautiful', 'garden', ',', 'carry', 'heavy', 'box', '.']\n",
      "\n",
      "Examples:\n",
      "  running → run\n",
      "  runner → runner\n",
      "  beautiful → beautiful\n",
      "\n",
      "============================================================\n",
      "\n",
      "COMPARISON - Stemming vs Lemmatization:\n",
      "Word            Stemmed         Lemmatized     \n",
      "---------------------------------------------\n",
      "the             the             the            \n",
      "runners         runner          runners        \n",
      "were            were            be             \n",
      "running         run             run            \n",
      "quickly         quickli         quickly        \n",
      "through         through         through        \n",
      "the             the             the            \n",
      "beautiful       beauti          beautiful      \n",
      "gardens         garden          garden         \n",
      "carrying        carri           carry          \n",
      "heavy           heavi           heavy          \n",
      "boxes           box             box            \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download required NLTK data (run once)\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Sample text\n",
    "text = \"The runners were running quickly through the beautiful gardens, carrying heavy boxes.\"\n",
    "\n",
    "print(\"Original text:\", text)\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Step 1: TOKENIZATION - Split text into individual words\n",
    "tokens = word_tokenize(text.lower())\n",
    "print(\"1. TOKENIZATION:\")\n",
    "print(tokens)\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Step 2a: STEMMING - Crude chopping to get word root\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_words = [stemmer.stem(word) for word in tokens]\n",
    "print(\"2a. STEMMING (Porter Stemmer):\")\n",
    "print(stemmed_words)\n",
    "print(\"\\nExamples:\")\n",
    "print(f\"  running → {stemmer.stem('running')}\")\n",
    "print(f\"  runner → {stemmer.stem('runner')}\")\n",
    "print(f\"  beautiful → {stemmer.stem('beautiful')}\")\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Step 2b: LEMMATIZATION - Intelligent reduction to dictionary form\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [lemmatizer.lemmatize(word, pos='v') for word in tokens]\n",
    "print(\"2b. LEMMATIZATION:\")\n",
    "print(lemmatized_words)\n",
    "print(\"\\nExamples:\")\n",
    "print(f\"  running → {lemmatizer.lemmatize('running', pos='v')}\")\n",
    "print(f\"  runner → {lemmatizer.lemmatize('runner', pos='n')}\")\n",
    "print(f\"  beautiful → {lemmatizer.lemmatize('beautiful', pos='a')}\")\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# COMPARISON TABLE\n",
    "print(\"COMPARISON - Stemming vs Lemmatization:\")\n",
    "print(f\"{'Word':<15} {'Stemmed':<15} {'Lemmatized':<15}\")\n",
    "print(\"-\" * 45)\n",
    "for token in tokens:\n",
    "    if token.isalpha():  # Only process words\n",
    "        stemmed = stemmer.stem(token)\n",
    "        lemmatized = lemmatizer.lemmatize(token, pos='v')\n",
    "        print(f\"{token:<15} {stemmed:<15} {lemmatized:<15}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae9af66",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487786c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    \"chat chat chien\",\n",
    "    \"chat souris\",\n",
    "    \"chien souris\",\n",
    "    \"chien souris chien\"\n",
    "]\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(docs)\n",
    "\n",
    "print(vectorizer.get_feature_names_out())\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdaa21b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mots du vocabulaire :\n",
      "['100' '213' '899' 'abstract' 'amount' 'an' 'and' 'ant' 'anti' 'apart'\n",
      " 'apparance' 'appeal' 'attention' 'beauty' 'body' 'box' 'brand' 'bright'\n",
      " 'bring' 'by' 'close' 'cm' 'color' 'contemporary' 'content' 'create'\n",
      " 'curtain' 'design' 'designed' 'dimension' 'door' 'draw' 'duster25'\n",
      " 'elegance' 'elegant' 'enhances' 'environment' 'evening' 'eyelet' 'fabric'\n",
      " 'feature' 'filter' 'first' 'floral' 'for' 'from' 'general' 'get' 'give'\n",
      " 'given' 'good' 'have' 'heart' 'height' 'high' 'home' 'id' 'in'\n",
      " 'interiors' 'is' 'it' 'joyous' 'key' 'length' 'light' 'look' 'loving'\n",
      " 'made' 'make' 'material' 'metal' 'model' 'modernistic' 'moment' 'morning'\n",
      " 'most' 'multicolor' 'name' 'number' 'of' 'pack' 'package' 'polyester'\n",
      " 'price' 'print' 'quality' 'ray' 'right' 'ring' 'romantic' 'room' 'sale'\n",
      " 'set' 'shrinkage' 'slide' 'smoothly' 'so' 'softly' 'soothing' 'special'\n",
      " 'specification' 'steal' 'stitch' 'style' 'sun' 'sunlight' 'sure'\n",
      " 'surreal' 'that' 'the' 'them' 'these' 'thing' 'this' 'to' 'type'\n",
      " 'valance' 'want' 'welcome' 'when' 'whole' 'wish' 'with' 'world' 'wrinkle'\n",
      " 'you' 'your']\n",
      "\n",
      "Matrice TF-IDF :\n",
      "[[0.03380617 0.10141851 0.03380617 0.13522468 0.03380617 0.03380617\n",
      "  0.20283702 0.03380617 0.03380617 0.03380617 0.03380617 0.03380617\n",
      "  0.03380617 0.03380617 0.03380617 0.03380617 0.03380617 0.06761234\n",
      "  0.03380617 0.03380617 0.03380617 0.10141851 0.03380617 0.03380617\n",
      "  0.03380617 0.03380617 0.37186787 0.06761234 0.03380617 0.03380617\n",
      "  0.16903085 0.06761234 0.03380617 0.13522468 0.06761234 0.03380617\n",
      "  0.03380617 0.03380617 0.20283702 0.03380617 0.06761234 0.03380617\n",
      "  0.03380617 0.03380617 0.03380617 0.03380617 0.03380617 0.03380617\n",
      "  0.03380617 0.03380617 0.03380617 0.03380617 0.03380617 0.06761234\n",
      "  0.03380617 0.06761234 0.03380617 0.23664319 0.03380617 0.10141851\n",
      "  0.06761234 0.03380617 0.03380617 0.03380617 0.03380617 0.03380617\n",
      "  0.03380617 0.03380617 0.03380617 0.03380617 0.03380617 0.06761234\n",
      "  0.03380617 0.03380617 0.06761234 0.03380617 0.13522468 0.03380617\n",
      "  0.03380617 0.3380617  0.10141851 0.06761234 0.20283702 0.03380617\n",
      "  0.03380617 0.03380617 0.03380617 0.03380617 0.03380617 0.03380617\n",
      "  0.06761234 0.06761234 0.03380617 0.03380617 0.03380617 0.03380617\n",
      "  0.06761234 0.03380617 0.03380617 0.03380617 0.03380617 0.03380617\n",
      "  0.03380617 0.03380617 0.03380617 0.03380617 0.03380617 0.03380617\n",
      "  0.06761234 0.43948021 0.06761234 0.06761234 0.03380617 0.10141851\n",
      "  0.13522468 0.03380617 0.03380617 0.03380617 0.03380617 0.06761234\n",
      "  0.03380617 0.03380617 0.06761234 0.03380617 0.03380617 0.16903085\n",
      "  0.06761234]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "list_description_str = ['key feature of elegance polyester multicolor abstract eyelet door curtain floral curtain , elegance polyester multicolor abstract eyelet door curtain ( 213 cm in height , pack of 2 ) price : r . 899 this curtain enhances the look of the interiors.this curtain is made from 100 % high quality polyester fabric.it feature an eyelet style stitch with metal ring.it make the room environment romantic and loving.this curtain is ant- wrinkle and anti shrinkage and have elegant apparance.give your home a bright and modernistic appeal with these design . the surreal attention is sure to steal heart . these contemporary eyelet and valance curtain slide smoothly so when you draw them apart first thing in the morning to welcome the bright sun ray you want to wish good morning to the whole world and when you draw them close in the evening , you create the most special moment of joyous beauty given by the soothing print . bring home the elegant curtain that softly filter light in your room so that you get the right amount of sunlight. , specification of elegance polyester multicolor abstract eyelet door curtain ( 213 cm in height , pack of 2 ) general brand elegance designed for door type eyelet model name abstract polyester door curtain set of 2 model id duster25 color multicolor dimension length 213 cm in the box number of content in sale package pack of 2 sale package 2 curtain body & design material polyester']\n",
    "\n",
    "\n",
    "# list_description_str doit être une liste de chaînes de texte, par exemple :\n",
    "# list_description_str = [\"texte 1\", \"texte 2\", \"autre texte\", ...]\n",
    "\n",
    "# 1. On crée un vectorizer TF-IDF\n",
    "vectorizer = TfidfVectorizer()  # transforme du texte en vecteurs numériques pondérés TF-IDF\n",
    "\n",
    "# 2. On apprend le vocabulaire (fit) et on transforme les textes en matrice TF-IDF (transform)\n",
    "X = vectorizer.fit_transform(list_description_str)\n",
    "\n",
    "# 3. Affiche les mots du vocabulaire (colonnes de la matrice TF-IDF)\n",
    "print(\"Mots du vocabulaire :\")\n",
    "print(vectorizer.get_feature_names_out())\n",
    "\n",
    "# 4. Affiche la matrice TF-IDF complète sous forme de tableau\n",
    "#    Chaque ligne = un texte ; chaque colonne = un mot du vocabulaire\n",
    "print(\"\\nMatrice TF-IDF :\")\n",
    "print(X.toarray())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b788121",
   "metadata": {},
   "source": [
    "# Word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570b2775",
   "metadata": {},
   "source": [
    "Word embeddings = vecteurs numériques pour chaque mot, appris à partir d’un grand corpus.  \n",
    "Exemple : word2vec(\"king\") - word2vec(\"man\") + word2vec(\"woman\") ≈ word2vec(\"queen\")\n",
    "\n",
    "Problème : tes modèles classiques donnent des vecteurs mot par mot, alors toi tu veux un vecteur par phrase/document.\n",
    "\n",
    "Solution simple : moyenne (average) ou pooling\n",
    "\n",
    "On prend tous les vecteurs des mots de la phrase\n",
    "\n",
    "On fait la moyenne → vecteur unique pour la phrase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06696d9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
